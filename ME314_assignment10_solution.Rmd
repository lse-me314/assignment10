---
title: "Assignment 10 - Text Classification and Scaling (Solutions)"
author: "Jack Blumenau"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##"
)
```

```{r, echo = FALSE, message=FALSE}
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(quanteda.textmodels)
```

In this assignment, you will use R to understand and apply document classification and supervised scaling using R and **quanteda**.

## Exercise 10.1 - Naive Bayes Classification of Movie Revies

We will start with a classic computer science dataset of movie reviews, [(Pang and Lee 2004)](http://www.cs.cornell.edu/home/llee/papers/cutsent.pdf). The movies corpus has an attribute `sentiment` that labels each text as either `pos` or `neg` according to the original imdb.com archived newspaper review star rating.  

To use this dataset, you will need to install the `quanteda.textmodels` package:

```{r, eval=FALSE}
install.packages("quanteda.textmodels")
library(quanteda.textmodels)
```

You can extract the relevant corpus object using the following line of code:

```{r}

moviereviews <- quanteda.textmodels::data_corpus_moviereviews

```

You should also load the `quanteda` package:

```{r, eval=FALSE}
library(quanteda)
```

Start by looking at the metadata included with this corpus using the `docvars()` function:

```{r, echpo = TRUE}

head(docvars(moviereviews))

```

We will be using the `sentiment` variable, which includes information from a human-labelling of movie reviews as either positive (`pos`) or negative (`neg`).

(a) Use the `table()` function to work out how many positive and how many negative movie reviews there are in the corpus.

```{r, echo = TRUE}

table(docvars(moviereviews)$sentiment)

```

(b) Use the code below to create a logical vector of the same length as the number of documents in the corpus. We will use this vector to define our training and test sets. Look at `?sample` to make sure you understand what each part of the code is doing. As we are using randomness to generate this vector, don't forget to first set your seed so that the results are fully replicable!

```{r}

set.seed(1234)

train <- sample(c(TRUE, FALSE), 2000, replace = TRUE, prob = c(.75, .25))

```

(c) Subset the corpus into a training set and a test set using the vector you just created. Use the square brackets to subset (i.e. `my_corpus[vector,]`) to do this. (Remember, if we use an exclamation point `!` before a logical vector, it will reverse the `TRUE` and `FALSE` values.)

```{r}

movies_train_corpus <- moviereviews[train]
movies_test_corpus <- moviereviews[!train]

```

d) Make a dfm for the training corpus (i.e. `dfm()`), and make some reasonable feature selection decisions to reduce the number of features in the dfm. Then make a dfm for the test corpus, and use the `dfm_match()` function to make sure that it contains the same set of features as the training dfm. See the example in the lecture if you are struggling, or consult the relevant help files.

<!-- from the shuffled corpus, and make training labels. In this case, we are using 1500 training labels, and leaving the remaining 500 unlabelled to use as a test set. We will also trim the dataset to remove rare features. -->

```{r}

movies_train_tokens <- tokens(movies_train_corpus, 
                              remove_punct = TRUE, 
                              remove_numbers = TRUE, 
                              remove_symbols = TRUE)

movies_test_tokens <- tokens(movies_test_corpus, 
                             remove_punct = TRUE, 
                             remove_numbers = TRUE, 
                             remove_symbols = TRUE)

movies_train_dfm <- dfm(movies_train_tokens) %>%
  dfm_remove(pattern = stopwords("en")) %>%
  dfm_trim(min_termfreq = 10)

movies_test_dfm <- dfm(movies_test_tokens)

movies_test_dfm <- dfm_match(movies_test_dfm, features = featnames(movies_train_dfm))


```

(e) Use the `textmodel_nb()` function to train the Naive Bayes classifier on the training dfm. You should use the dfm you created for the training corpus as the `x` argument to this function, and the outcome (i.e. `training_dfm$sentiment`) as the `y` argument.

```{r}

movie_nb <- textmodel_nb(movies_train_dfm, movies_train_dfm$sentiment)

```

(f) Examine the `param` element of the fitted model. Which words have the highest probability under the `pos` class? Which words have the highest probability under the `neg` class? You might find the `sort()` function helpful here.

```{r}

head(sort(movie_nb$param[2,], decreasing = TRUE), 40)

head(sort(movie_nb$param[1,], decreasing = TRUE), 40)

```

(g) Use the `predict()` function to predict the sentiment of movies in the test set dfm. The predict function takes two arguments in this instance: 1) the estimated Naive Bayes model from part (e), and 2) the test-set dfm. Create a confusion matrix of the predicted classes and the actual classes in the test data. What is the accuracy of your model?

```{r}

movie_test_predicted_class <- predict(movie_nb, newdata = movies_test_dfm)

movie_confusion <- table(movie_test_predicted_class, movies_test_dfm$sentiment)

movie_confusion

## Accuracy
mean(movie_test_predicted_class == movies_test_dfm$sentiment)

```

(h) Load the `caret` package (install it first using `install.packages()` if you need to), and then use the `confusionMatrix()` function to calculate other statistics relevant to the predictive performance of your model. The first argument to the `confusionMatrix()` function should be the confusion matrix that you created in answer to question (g). You should also set the `positive` argument equal to `"pos"` to tell R the level of the outcome that corresponds to a "positive" result. Report the the accuracy, sensitivity and specificity of your predictions, giving a brief interpretation of each.

```{r}

library(caret)

movie_confusion_statistics <- confusionMatrix(movie_confusion, positive = "pos")

movie_confusion_statistics

```

**Accuracy: The proportion of observations correctly classified is `r movie_confusion_statistics$overall[1]`.**

**Sensitivity: The proportion of "positive" movie reviews correctly classified is `r movie_confusion_statistics$byClass[1]`.**

**Specificity: The proportion of "negative" movie reviews correctly classified is `r movie_confusion_statistics$byClass[2]`.**

## Exercise 10.2 - Wordscores for Movie Reviews

(a) We will now use the same training and test set to estimate wordscores for the movie reviews. First, create a new variable (named `refscore`) for the training set dfm which is equal to 1 for positive movie reviews, and -1 for negative movie reviews. These are the reference scores that we will use for training the model.

```{r}

movies_train_dfm$refscore <- ifelse(movies_train_dfm$sentiment == "pos", 1, -1)

```

(b) Use the `textmodel_wordscores()` function to estimate wordscores on the training dfm. This function requires two arguments: 1) `x`, for the dfm you are using to estimate the model, and 2) `y` for the vector of reference scores associated with each training document (i.e. the variable you created in the answer above).

```{r}

wordscore_model <- textmodel_wordscores(movies_train_dfm, movies_train_dfm$refscore)

```

(c) Predict the wordscores for the test set using the predict function. Again, for `predict()` to work, you need to pass it the trained wordscores model, and the test set dfm. Save your predictions as a new metadata variable in your training data dfm.

```{r}

movies_test_dfm$wordscores <- predict(wordscore_model, movies_test_dfm)

```

(d) Use the `docvars()` function on your test set dfm to check that you have correctly assigned the predictions as meta data (hint: if you have done (c) correctly, then when you run `str(docvars(my_test_set_dfm))` you should see a column containing the estimated wordscores).

```{r}

str(docvars(movies_test_dfm))

```

(e) Use the `boxplot()` function to compare the distribution of wordscores against the "true" sentiment of the reviews given by human annotators (look at `?boxplot` to see how to create the plot). Describe the resulting pattern. 

```{r, fig.width = 3, fig.height = 5}

boxplot(movies_test_dfm$wordscores ~ movies_test_dfm$sentiment, ylab = "Raw wordscore")

```

**Our model appears to do a pretty good job of assigning more positive scores to "positive" movie reviews.**

(f) Look for examples of texts with positive wordscores (for instance, any text with a wordscore greater than 0.075) that are nonetheless categorised as "negative" by human readers. Look for examples of texts with negative wordscores (for instance, any text with a wordscore smaller than -0.03) that are nonetheless categorised as "positive" by human readers. Why do you think the model gave the wrong predictions in those cases? 

Hint: you may want to use logical relations to find the texts you are looking for. For instance, using `my_vetor > 0.05` will return a logical vector which is equal to `TRUE` when `my_vector` is greater than 0.05 and `FALSE` otherwise. Similarly, `my_vector == "a string I want"` will return a logical vector which is equal to `TRUE` when `my_vector` is equal to "a string I want" and `FALSE` otherwise.

Hint 2: You can extract the full texts from your corpus object by using `as.character(my_corpus)` with the appropriate subsetting operator (i.e. `[,]`).

```{r}

as.character(movies_test_corpus)[movies_test_dfm$wordscores > .075 & movies_test_dfm$sentiment == "neg"]

```


```{r}

as.character(movies_test_corpus)[movies_test_dfm$wordscores < -.03 & movies_test_dfm$sentiment == "pos"]

```

**The model fails in these cases because the reviews contain a lot of words of the opposite class which generally explain the subject matter of the movie, rather than expressing sentiment *about* the movie.**

## Exercise 10.3 - Wordfish for Irish Parliamentary Debates (Hard question)

In this part of the assignment, you will use R to understand and apply unsupervised document scaling. Use the `data_corpus_irishbudget2010` in **quanteda.textmodels** for this. You will also need to load (and possible install) the `quanteda.textplots` package first.

a) Fit a wordfish model of all the documents in this corpus. Apply any required preprocessing steps first. Use the `textplot_scale1d` function to visualize the result. (You may want to use the advanced options of this function to get a better plot than just the default one.) 

What do you learn about what the dimension is capturing? You can use wikipedia to learn about the Irish parties involved in this debate to help you answer this question.


```{r}

library(quanteda.textplots)

irish_tokens <- tokens(data_corpus_irishbudget2010, remove_punct = TRUE) %>%
  tokens_wordstem()

irish_dfm <- dfm(irish_tokens) %>%
  dfm_remove(pattern = stopwords("en"))

wordfish_model <- textmodel_wordfish(irish_dfm)

textplot_scale1d(wordfish_model, groups = data_corpus_irishbudget2010$party)

```

**The model is capturing a government vs opposition dimension rather than a left-right dimension. $\theta$ is opposition score, so Labour is more often in opposition in 2010**

b) Plot the wordfish "Eiffel Tower" plot (as in Figure 2 of Slapin and Proksch 2008), from the wordfish object. You can do this using the `textplot_scale1d` function. What is your interpretation of these results?

```{r, fig.width = 5, fig.height = 5}

textplot_scale1d(wordfish_model, margin = "features")

```

**In this case, the plot is very hard to interpret! There is some evidence that "citizenship" is an especially discriminating word on the estimated dimension, but the other words are hard to make sense of (because they are difficult to see). It is somewhat easier to just extract the most discriminating words at each end of the dimension, as follows: **

```{r}

head(wordfish_model$features[order(wordfish_model$beta, decreasing = T)])

head(wordfish_model$features[order(wordfish_model$beta, decreasing = F)])

```

**Even now, however, it is hard to know what this dimension "means" in any real sense. Perhaps it would be easier if you had a PhD in Irish Politics (which I do not). Let this serve as a cautionary tale about the difficulties of unsupervised learning for text!**

c) Plot the log of the length in tokens of each text against the $\hat{\alpha}$ from your estimated wordfish model. What does the relationship indicate? (Hint: you can use the `ntoken()` function on your dfm to extract the number of words in each text.)

```{r, fig.width = 5, fig.height = 5}
plot(x = log(ntoken(irish_dfm)), 
     y = wordfish_model$alpha, pch = 19,
     xlab="log token count for each document",
     ylab="estimated alpha")
```

**It shows that the alpha parameter is measuring how much each politician speaks.**

d) Plot the log of the frequency of the top most frequent 1000 words against the same psi-hat values from your estimated wordfish model, and describe the relationship. The `topfeatures()` function might be helpful here.

```{r, fig.width = 5, fig.height = 5}
# finding top 1,000 words
top1000 <- topfeatures(irish_dfm, n=1000)
top1000 <- data.frame(word = names(top1000), 
                      freq = as.numeric(top1000),
                    stringsAsFactors = FALSE)

# extracting the estimated psi parameters
df <- data.frame(
  word = wordfish_model$features,
  psi_hat = wordfish_model$psi,
  stringsAsFactors=FALSE
)

# Merge the word counts with the estimated word-level coefficients

df <- merge(df, top1000)

# Plot the result

plot(
  x = log(df$freq),
  y = df$psi_hat,
  pch = 19, col = "gray",
  xlab = "log(word frequency)",
  ylab = "estimated psi"
)
```

**Psi captures the log frequency with which each word appears in the corpus.**
